# AIRI VTuber 文本到语音(TTS)完整解析：从配置到实现

AIRI VTuber 是一个先进的虚拟主播系统，能够将用户输入的文本转换为自然语音，并驱动虚拟角色进行说话。本文将深入解析 AIRI 中文本到语音的完整流程，包括语音服务配置和实现细节。

## 语音服务配置

在 AIRI 中，你可以配置多种语音服务提供商，包括云端服务（如 ElevenLabs、Microsoft Speech）和本地服务（如 Index-TTS）。以下以 Index-TTS 为例介绍配置过程：

### Index-TTS 配置步骤

1. 进入 AIRI 设置界面，选择 "Speech" 部分
2. 选择 "Index-TTS by Bilibili" 作为语音提供者
3. 配置服务地址，默认为 `http://localhost:11996/tts`
4. 保存配置

确保本地已运行 Index-TTS 服务，AIRI 将通过该地址与服务通信进行语音合成。

## 文本到语音转换流程详解

### 1. 用户输入文本

用户在 AIRI 主界面的输入框中输入需要转换为语音的文本内容。

### 2. 文本处理与队列管理

当用户发送文本后，系统首先将其分段处理：

```typescript
const ttsQueue = createQueue<string>({
  handlers: [
    handleSpeechGeneration,
  ],
})

const messageContentQueue = useMessageContentQueue(ttsQueue)

// 当收到文本 token 时触发语音生成
onTokenLiteral(async (literal) => {
  messageContentQueue.enqueue(literal)
})
```

### 3. 语音生成核心处理

系统根据配置的语音提供者生成语音：

```typescript
async function handleSpeechGeneration(ctx: { data: string }) {
  try {
    // 检查是否配置了语音提供者和声音
    if (!activeSpeechProvider.value) {
      console.warn('No active speech provider configured')
      return
    }

    if (!activeSpeechVoice.value) {
      console.warn('No active speech voice configured')
      return
    }

    // 获取配置的语音提供者实例
    const provider = await providersStore.getProviderInstance(activeSpeechProvider.value)
    if (!provider) {
      console.error('Failed to initialize speech provider')
      return
    }

    const providerConfig = providersStore.getProviderConfig(activeSpeechProvider.value)

    // 处理文本输入（根据是否启用 SSML）
    const input = ssmlEnabled.value
      ? speechStore.generateSSML(ctx.data, activeSpeechVoice.value, { ...providerConfig, pitch: pitch.value })
      : ctx.data

    // 调用 generateSpeech 函数生成语音
    const res = await generateSpeech({
      ...provider.speech(activeSpeechModel.value, providerConfig),
      input,
      voice: activeSpeechVoice.value.id,
    })

    // 将生成的语音数据解码为 AudioBuffer
    const audioBuffer = await audioContext.decodeAudioData(res)
    audioQueue.enqueue({ audioBuffer, text: ctx.data })
  }
  catch (error) {
    console.error('Speech generation failed:', error)
  }
}
```

### 4. 调用具体的语音服务

对于 Index-TTS，系统会：

1. 使用配置的 baseUrl（默认 `http://localhost:11996/tts`）
2. 构造包含文本、声音和模型信息的请求
3. 发送到 Index-TTS 服务进行语音合成
4. 接收返回的音频数据

### 5. 音频播放与角色动画

生成的音频通过 Web Audio API 播放，并同时驱动 VTuber 模型的唇形同步：

```typescript
const audioQueue = createQueue<{ audioBuffer: AudioBuffer, text: string }>({
  handlers: [
    (ctx) => {
      return new Promise((resolve) => {
        // 创建音频源
        const source = audioContext.createBufferSource()
        source.buffer = ctx.data.audioBuffer

        // 连接到音频输出设备
        source.connect(audioContext.destination)
        // 连接到音频分析器（用于唇形同步）
        source.connect(audioAnalyser.value!)

        // 开始播放音频
        nowSpeaking.value = true
        currentAudioSource = source
        source.start(0)
        source.onended = () => {
          nowSpeaking.value = false
          if (currentAudioSource === source) {
            currentAudioSource = null
          }
          resolve()
        }
      })
    },
  ],
})
```

## 支持的语音服务提供商

AIRI 支持多种语音服务提供商，包括：

1. **云端服务**：
   - ElevenLabs
   - Microsoft Azure Speech
   - OpenAI TTS
   - Alibaba Cloud Model Studio

2. **本地服务**：
   - Index-TTS (Bilibili)
   - Edge TTS
   - 浏览器内置 TTS

## 配置自定义语音服务

如果你想要配置自己的语音服务，可以：

1. 选择 "OpenAI Compatible" 作为语音提供者
2. 配置自定义的 API 地址
3. 设置相应的认证信息（如 API Key）
4. 选择合适的声音和模型

## 总结

AIRI VTuber 的文本到语音系统采用模块化设计，支持多种语音服务提供商。通过灵活的配置和高效的处理流程，能够实现从文本输入到语音播放的完整转换过程。系统还集成了唇形同步功能，使得虚拟角色的说话表现更加自然生动。

整个流程自动化程度高，用户只需关注内容创作，系统会自动处理文本分割、语音合成和音频播放等复杂过程，为用户提供流畅的虚拟主播体验。
